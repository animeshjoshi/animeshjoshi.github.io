<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Animesh Joshi's Portfolio</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>

<header>
    <img src="your-photo.jpg" alt="Animesh Joshi">
    <h1>Animesh Joshi</h1>
    <p>Mathematics and Statistics Student at Purdue University | Aspiring Data Scientist</p>
</header>

<nav>
    <ul>
        <li><a href="#about">About</a></li>
        <li><a href="#experience">Experience</a></li>
        <li><a href="#education">Education</a></li>
        <li><a href="#projects">Projects</a></li>
      <li><a href="#resume">Resume</a></li>
        <li><a href="#social-links">Contact</a></li>
     
    </ul>
</nav>

<section id="about">
    <h2>About Me</h2>
    <p>Hi! I'm an undergraduate student at Purdue University majoring in Mathematics and Statistics. I will be working as a data management intern at Dexcom this summer and previously worked at Axos Bank as a Credit Risk Analytics intern. I am doing research at Purdue focused on understanding fairness violations in machine learning and identifying data points that cause these violations. More generally, I am interested in Statistical Inference, Causal Inference, Econometrics, and Machine Learning.</p>
</section>

<section id="experience">
    <h2>Internships</h2>

    <div class="internship">
      <h3><a href="#dexcomModal" class="internship-link" data-toggle="modal">Data Management Intern at Dexcom</a></h3>
      <p>Incoming Intern at Dexcom. In this role, I will be working on manufacturing data management and validation.</p>
    </div>

    <div class="internship">
      <h3><a href="#axosModal" class="internship-link" data-toggle="modal">Credit Analytics Intern at Axos Bank</a></h3>
      <p>In this role, I worked in the credit analytics department to provide data analytics solutions for commercial lending strategy. The primary project I worked on was building a report to show monthly trends in key lending metrics (LTV, FICO, Utilization Rate, etc.) for loan originations. I also built a report to show monthly trends in key lending metrics for all loans in the banks' portfolio. These trends were presented alongside trends in delinquency to establish which risk metrics were the drivers of loan delinquencies and defaults. I also worked on ad-hoc reporting tickets which involved editing and optimizing reports used for asset management and regulatory compliance.</p>
    </div>

    <div class="internship">
      <h3><a href="#purdueInternshipModal" class="internship-link" data-toggle="modal">Responsible Data Science Researcher at Purdue University (2024-2025 Academic Year)</a></h3>
      <p>During this research experience, I had the opportunity to learn about responsible data management and machine learning. I trained a logistic regression classifier to predict credit ratings for prospective loan applicants. I developed a script to calculate machine learning fairness metrics based on a peer-reviewed paper. These metrics included well calibration, equalized odds, causal discrimination, and fairness through unawareness. I am currently working on identifying which data points contribute to model bias through the use of shapley values and influence functions. I am prototyping an estimation of the influence value and testing to see if estimated influence values align with "ground-truth" values obtained through leave-one-out approach.</p>
    </div>

    <h2>Research</h2>

  
    <div class="research">
      <h3><a href="#mlResearchModal" class="research-link" data-toggle="modal">ML Researcher at Purdue University (2024-2025 Academic Year)</a></h3>
      <p>During this experience, I learned about state-of-the-art topics in machine learning. I began this experience by learning about foundation models, such as transformers and diffusion models. I worked on background tasks for a project on solving stochastic PDEs using diffusion models. These background tasks included recreating a dataset of stochastic PDEs and their solutions that was used in a prior study, prototyping diffusion hyperparameter optimization using optuna, and implementing a probabilistic diffusion model from scratch. I also performed literature reviews to learn about topics such as diffusion models, masked autoencoders, and partial differential equations. Later on, I worked for a bit on a project which involved graph diffusion policy optimization. I worked to reproduce the results of a prior study that used graph diffusion policy optimization for generative modeling of chemical structures of drugs. Currently, I am learning more about optimal transport and learning a continuous trajectory between distributions using stochastic samples from each distribution.</p>
    </div>

    <div class="research">
      <h3><a href="#mlFairnessModal" class="research-link" data-toggle="modal">ML Researcher at Purdue University (2024-2025 Academic Year)</a></h3>
      <p>During this research experience, I had the opportunity to learn about responsible data management and machine learning. I trained a logistic regression classifier to predict credit ratings for prospective loan applicants. I developed a script to calculate machine learning fairness metrics based on a peer-reviewed paper. These metrics included well calibration, equalized odds, causal discrimination, and fairness through unawareness. I am currently working on identifying which data points contribute to model bias through the use of shapley values and influence functions. I am prototyping an estimation of the influence value and testing to see if estimated influence values align with "ground-truth" values obtained through leave-one-out approach.</p>
    </div>
</section>

<!-- Modal for Algae Project PDF -->
<div id="algaeProjectModal" class="modal">
  <div class="modal-content">
    <span class="close">&times;</span>
    <h3>Data Science Researcher at Purdue University (2022-2023 Academic Year)</h3>
    <p>This experience was a corporate partnership as part of the Data Mine learning community. In this role, I worked on identifying algal contamination in lakes and rivers within the State of Indiana. I collected satellite image data from the sentinel hub EO browser and leveraged methods such as image tiling and data augmentations to build a dataset of true color image tiles and corresponding water quality masks. I then developed a U-Net model for semantic segmentation to create a water quality mask from a true color image tile in order to assess where in a lake or river water quality issues existed. I also helped fine-tune a pretrained ResNet50 classifier to detect true color image tiles that showed signs of significant algae contamination. I presented my findings along with my group at the annual Data Mine Symposium.</p>
    <iframe src="algae_project.pdf" width="100%" height="500px"></iframe>
  </div>
</div>

</section>

<!-- Modals for other sections -->
<!-- Add modals for other internships/research projects as needed -->


<section id="education">
    <h2>Education</h2>

    <div class="education-card">
        <h3>Purdue University</h3>
        <p><strong>B.S. in Mathematics, B.S. in Statistics, Certificate in Applied Data Science</strong></p>
        <p><strong>Expected Graduation:</strong> Dec 2025</p>
        <h4>Relevant Coursework:</h4>
        <ul>
            <li><strong>Statistical Theory</strong>: Point Estimation, Interval Estimation, Hypothesis Testing, Likelihood Ratio Tests, Linear Regression, Autoregression, Bayesian Estimation</li>
            <p>This course helped me build a strong foundation in statistical theory, focusing on how to derive and test estimators and make inferences from data.</p>
            
            <li><strong>Operations Research</strong>: Mathematical Modeling, Linear Programming, Duality, Sensitivity Analysis, Network Flows, Mixed Integer Programming, Game Theory</li>
            <p>This course taught me how to model complex decision-making processes using mathematical methods and algorithms, which is crucial for optimization problems in data science.</p>

            <li><strong>Signals and Systems</strong>: Convolutions, Hilbert Spaces, Fourier Series, Discrete Fourier Transform, Fast Fourier Transform, Filters, Sampling, Image Processing</li>
            <p>I gained an understanding of how signals are processed, especially in the context of data analysis and machine learning applications that involve signal processing.</p>

            <li><strong>Analysis</strong>: Mathematical Induction, Sets, Topology, Limits, Sequences, Series, Derivatives, Taylor Series, Integration</li>
            <p>This course refined my understanding of advanced mathematical concepts, which are foundational to statistical and machine learning theory.</p>

            <li><strong>Epidemiology</strong>: Disease Measurement, Screening, Survival Analysis, Study Designs, Measures of Association, Statistical Inference, Bias, Confounding, Interaction, Regression, Causal Inference, Policy Design</li>
            <p>This course helped me apply statistical principles in the context of public health, emphasizing causal inference and the design of observational studies.</p>

            <li><strong>Regression Analysis</strong>: Simple Linear Regression, T-Tests and ANOVA, Variable Transformations, Normality and Homoscedasticity Violations, Simultaneous Inference, Multiple Linear Regression, MLR ANOVA, Weighted Least Squares, Ridge Regression, Bootstrapping, Robust Regression, Interaction Terms, Categorical Data Analysis</li>
            <p>A comprehensive course where I learned how to handle various regression models, including handling violations of assumptions and using techniques like bootstrapping for more robust inference.</p>

            <li><strong>Statistical Learning</strong>: Linear Regression, Linear Discriminant Analysis, Logistic Regression, Decision Trees, Random Forest Algorithms, Boosting</li>
            <p>This course introduced me to machine learning algorithms and model evaluation techniques, equipping me with tools to work with complex datasets.</p>

            <li><strong>Probability</strong>: Combinatorics, Discrete Probability Distributions, Poisson Distribution, Exponential Distributions, Gamma Distributions, Normal Distributions, Joint PDFs, Random Variable Transformations, Limit Theorems</li>
            <p>I learned the fundamentals of probability theory, which is the backbone of statistical modeling and machine learning.</p>

            <li><strong>Introductory Statistics</strong>: Discrete Probability Distributions, Continuous Probability Distributions, Confidence Intervals, Hypothesis Testing, ANOVA, Linear Regression</li>
            <p>A foundational course where I gained practical experience with statistical analysis techniques, laying the groundwork for more advanced courses.</p>

            <li><strong>Linear Algebra</strong>: Gaussian Elimination, Linear Combinations and Span, Vector Spaces, Linear Independence, Subspace, Basis and Dimensions, Determinants, Eigenvalues, Least Squares, Principal Component Analysis, Singular Value Decomposition</li>
            <p>I learned how to work with high-dimensional data, crucial for machine learning algorithms such as Principal Component Analysis (PCA) and Singular Value Decomposition (SVD).</p>

            <li><strong>Programming in C</strong>: Arrays, Pointers, Linked Lists, Stacks, Queues, Heaps, Binary Search Trees, Memory Allocation, Error Handling, Optimization, Rust, File Management</li>
            <p>This course provided a deep dive into data structures and algorithms, which are essential for writing efficient and optimized code for data manipulation.</p>

            <li><strong>Discrete Mathematics</strong>: Logic, Sets, Number Systems, Counting, Algorithm Analysis, Time Complexity, Graphs, Trees, Proofs, Recursion, Number Theory, Finite State Machines, Automata, Computability</li>
            <p>I learned core concepts in computer science and mathematics, which helped me understand how to solve computational problems and analyze algorithm efficiency.</p>
        </ul>
    </div>
</section>

    <section id="projects">
    <h2>Personal Projects</h2>

    <div class="project">
      <h3><a href="#recidivismModal" class="project-link" data-toggle="modal">Statistical Inference for ML Fairness Metrics and Application to Recidivism Risk Forecasting</a></h3>
      <p>Developing statistical inference procedures for ML fairness metrics defined in peer-reviewed study (https://fairware.cs.umass.edu/papers/Verma.pdf). Training various machine learning algorithms (Logistic Regression, LDA, Random Forest, Gradient Boosting) to forecast recidivism given data collected by the National Institute of Justice and evaluating model bias using developed inference procedures. Planning to submit to IEEE Big Data Conference.</p>
      <p><a href="https://github.com/animeshjoshi/Algorithmic-Fairness-in-Recidivism-Forecasting-Algorithms">GitHub Link</a></p>
    </div>

    <div class="project">
      <h3><a href="#utilityModal" class="project-link" data-toggle="modal">Utility Function for NFL Pass Plays and Defender Value Estimation</a></h3>
      <p>Developed a utility function to quantify expected reward of passing plays. Utility of a play is probability of pass completion multiplied by projected yardage gain. Trained ML algorithms to estimate pass completion probability and projected yardage gain after the catch. Analyzed trends in utility over time after the snap. Computed marginal utility of defenders to estimate their value on the play and analyzed trends in marginal utility over time.</p>
      <p><a href="https://github.com/animeshjoshi/nfl-data-bowl-25">GitHub Link</a></p>
    </div>

    <div class="project">
      <h3><a href="#secureComputingModal" class="project-link" data-toggle="modal">Secure Computing Environment for Predictive Modeling and Generative AI</a></h3>
      <p>Used cloud technologies to create a secure computing environment or "data clean room". Conducted exploratory data analysis and visualization to assess differences between regular website visitors and potential customers. Trained random forest algorithm to predict whether or not a website visitor would become a potential customer. Used CTGAN (Conditional Tabular GAN) to create synthetic dataset of website interactions to match distribution of provided dataset. Created powerpoint presentation to share findings with public.</p>
      <p><a href="https://github.com/animeshjoshi/Secure-Computing-Framework-for-AI">GitHub Link</a></p>
      <div class="pdf">
        <a href="securecomputing.pdf" target="_blank">Download PDF</a>
      </div>
    </div>

    <div class="project">
      <h3>Drivers of Disposable Personal Income Growth</h3>
      <p>Compiled dataset of macroeconomic indicators (investment, consumption, imports, exports, debt levels, etc.) from the St. Louis Federal Reserve. Explored dataset using various methods such as histograms, contingency tables, and summary statistics. Tested regression assumptions using variance inflation factors, Shapiro tests, qq-plots, residual plots, and Breusch Pagan test. Conducted regression analysis to determine which macroeconomic indicators have a significant impact on disposable personal income. Handled heteroscedasticity using weighted least squares approach and used bootstrapped confidence intervals for hypothesis testing. Validated model accuracy using k-fold cross validation.</p>
      <p><a href="https://github.com/animeshjoshi/dpi_regression">GitHub Link</a></p>
      <div class="pdf">
        <a href="dpi_regression.pdf" target="_blank">Download PDF</a>
      </div>
    </div>

    <div class="project">
      <h3>E-Commerce Marketplace Web Application</h3>
      <p>Built a full-stack e-commerce marketplace application. Application included login page for security purposes with account information permanently stored in internal data structures. Sellers had ability to list items at various different price points with automatically updating quantity counts. Buyers had ability to browse marketplace and purchase items. Special features included ability for a seller to automatically begin a sale and ability for a buyer to save items to a shopping cart. Application was fully concurrent and could be used simultaneously across multiple devices.</p>
      <p>Note: No GitHub link for this project.</p>
    </div>
</section>

<!-- Modal for Recidivism Project -->
<div class="modal" id="recidivismModal">
  <div class="modal-content">
    <span class="close">&times;</span>
    <h2>Statistical Inference for ML Fairness Metrics and Application to Recidivism Risk Forecasting</h2>
    <embed src="fairnessinference.pdf" width="100%" height="500px" type="application/pdf">
  </div>
</div>

<!-- Modal for Utility Project -->
<div class="modal" id="utilityModal">
  <div class="modal-content">
    <span class="close">&times;</span>
    <h2>Utility Function for NFL Pass Plays and Defender Value Estimation</h2>
    <embed src="utility.pdf" width="100%" height="500px" type="application/pdf">
  </div>
</div>

<!-- Modal for Secure Computing Project -->
<div class="modal" id="secureComputingModal">
  <div class="modal-content">
    <span class="close">&times;</span>
    <h2>Secure Computing Environment for Predictive Modeling and Generative AI</h2>
    <embed src="securecomputing.pdf" width="100%" height="500px" type="application/pdf">
  </div>
</div>





  <section id="resume">
    <h2>Resume</h2>
    <a href="Resume.pdf" target="_blank">Download Resume</a>
  </section>

  <section id="social-links">
    <div class="social-links">
      <a href="https://linkedin.com/in/animesh-joshi-664826237/" target="_blank" class="social-icon">
        <i class="fab fa-linkedin"></i>
      </a>
      <a href="https://github.com/animeshjoshi" target="_blank" class="social-icon">
        <i class="fab fa-github"></i>
      </a>
      <a href="mailto:animeshjoshi88@gmail.com" target="_blank" class="social-icon">
        <i class="fas fa-envelope"></i>
      </a>
    </div>
  </section>
</body>
</html>
